{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_local': './my-copy-c4', 'data_remote': None, 'max_seq_len': 2048, 'global_seed': 17, 'run_name': None, 'model': {'name': 'mpt_causal_lm', 'init_device': 'meta', 'd_model': 768, 'n_heads': 12, 'n_layers': 12, 'expansion_ratio': 4, 'max_seq_len': 2048, 'vocab_size': 50368, 'attn_config': {'attn_impl': 'triton'}}, 'tokenizer': {'name': 'EleutherAI/gpt-neox-20b', 'kwargs': {'model_max_length': 2048}}, 'train_loader': {'name': 'text', 'dataset': {'local': './my-copy-c4', 'remote': None, 'split': 'train', 'shuffle': True, 'max_seq_len': 2048, 'shuffle_seed': 17}, 'drop_last': True, 'num_workers': 8}, 'eval_loader': {'name': 'text', 'dataset': {'local': './my-copy-c4', 'remote': None, 'split': 'val', 'shuffle': False, 'max_seq_len': 2048, 'shuffle_seed': 17}, 'drop_last': False, 'num_workers': 8}, 'scheduler': {'name': 'cosine_with_warmup', 't_warmup': '100ba', 'alpha_f': 0.1}, 'optimizer': {'name': 'decoupled_adamw', 'lr': 0.0006, 'betas': [0.9, 0.95], 'eps': 1e-08, 'weight_decay': 0.0}, 'algorithms': {'gradient_clipping': {'clipping_type': 'norm', 'clipping_threshold': 1.0}}, 'max_duration': '4800ba', 'eval_interval': '500ba', 'eval_first': False, 'eval_subset_num_batches': -1, 'global_train_batch_size': 256, 'seed': 17, 'device_eval_batch_size': 16, 'device_train_microbatch_size': 16, 'precision': 'amp_bf16', 'fsdp_config': {'sharding_strategy': 'FULL_SHARD', 'mixed_precision': 'PURE', 'activation_checkpointing': False, 'activation_checkpointing_reentrant': False, 'activation_cpu_offload': False, 'limit_all_gathers': True}, 'progress_bar': False, 'log_to_console': True, 'console_log_interval': '1ba', 'callbacks': {'speed_monitor': {'window_size': 10}, 'lr_monitor': {}, 'memory_monitor': {}, 'runtime_estimator': {}}}\n"
     ]
    }
   ],
   "source": [
    "#\"train/launcher.py train/train.py /mnt/config/parameters.yaml train_loader.dataset.split=train eval_loader.dataset.split=val\"\n",
    "\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "from omegaconf import OmegaConf as om\n",
    "\n",
    "yaml_path = \"/Users/yu.gong/workspace/mosaic/llm-foundry/scripts/train/yamls/pretrain/mpt-125m.yaml\"\n",
    "args_list = [\"train_loader.dataset.split=train\", \"eval_loader.dataset.split=val\"]\n",
    "om.clear_resolver('oc.env')\n",
    "\n",
    "    # Load yaml and cli arguments.\n",
    "with open(yaml_path) as f:\n",
    "    yaml_cfg = om.load(f)\n",
    "cli_cfg = om.from_cli(args_list)\n",
    "cfg = om.merge(yaml_cfg, cli_cfg)\n",
    "om.resolve(cfg)\n",
    "\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_paths: [], max_split_size_mb: None, cuda_load_lazy: False, dist_timeout: 600.0\n"
     ]
    }
   ],
   "source": [
    "from llmfoundry.utils.config_utils import  pop_config\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import copy\n",
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "from composer import Trainer\n",
    "from composer.core.callback import Callback\n",
    "from composer.loggers import MosaicMLLogger, MLFlowLogger\n",
    "from composer.loggers.mosaicml_logger import (MOSAICML_ACCESS_TOKEN_ENV_VAR,\n",
    "                                              MOSAICML_PLATFORM_ENV_VAR)\n",
    "from composer.metrics.nlp import InContextLearningMetric\n",
    "from composer.profiler import (JSONTraceHandler, Profiler, TraceHandler,\n",
    "                               cyclic_schedule)\n",
    "from composer.utils import dist, get_device, reproducibility\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "from omegaconf import OmegaConf as om\n",
    "from rich.traceback import install\n",
    "\n",
    "install()\n",
    "\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "from llmfoundry import COMPOSER_MODEL_REGISTRY\n",
    "from llmfoundry.callbacks import AsyncEval\n",
    "from llmfoundry.data.dataloader import build_dataloader\n",
    "from llmfoundry.registry import import_file\n",
    "from llmfoundry.utils.builders import (add_metrics_to_eval_loaders,\n",
    "                                       build_algorithm, build_callback,\n",
    "                                       build_evaluators, build_logger,\n",
    "                                       build_optimizer, build_scheduler,\n",
    "                                       build_tokenizer)\n",
    "from llmfoundry.utils.config_utils import (log_config, pop_config,\n",
    "                                           process_init_device,\n",
    "                                           update_batch_size_info)\n",
    "import contextlib\n",
    "import logging\n",
    "import math\n",
    "import warnings\n",
    "from typing import Any, Dict, Literal, Mapping, Optional, Tuple, Union\n",
    "\n",
    "from composer.utils import dist\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "from omegaconf import OmegaConf as om\n",
    "\n",
    "\n",
    "code_paths = pop_config(cfg,\n",
    "                            'code_paths',\n",
    "                            must_exist=False,\n",
    "                            default_value=[],\n",
    "                            convert=True)\n",
    "\n",
    "max_split_size_mb: Optional[int] = cfg.pop('max_split_size_mb', None)\n",
    "cuda_load_lazy: bool = cfg.pop('cuda_load_lazy', False)\n",
    "dist_timeout: Union[int, float] = pop_config(cfg,\n",
    "                                                 'dist_timeout',\n",
    "                                                 must_exist=False,\n",
    "                                                 default_value=600.0)\n",
    "\n",
    "print(f\"code_paths: {code_paths}, max_split_size_mb: {max_split_size_mb}, cuda_load_lazy: {cuda_load_lazy}, dist_timeout: {dist_timeout}\")\n",
    "# glbal_train_batch_size 256, device_train_microbatch_size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_config: {'name': 'EleutherAI/gpt-neox-20b', 'kwargs': {'model_max_length': 2048}}\n",
      "model: {'name': 'mpt_causal_lm', 'init_device': 'meta', 'd_model': 768, 'n_heads': 12, 'n_layers': 12, 'expansion_ratio': 4, 'max_seq_len': 2048, 'vocab_size': 50368, 'attn_config': {'attn_impl': 'triton'}}\n"
     ]
    }
   ],
   "source": [
    "model_config: DictConfig = pop_config(cfg, 'model', must_exist=True)\n",
    "tokenizer_config: Dict[str, Any] = pop_config(cfg,\n",
    "                                                  'tokenizer',\n",
    "                                                  must_exist=True,\n",
    "                                                  convert=True)\n",
    "# tokenizer_config: {'name': 'EleutherAI/gpt-neox-20b', 'kwargs': {'model_max_length': 2048}}\n",
    "# model: {'name': 'mpt_causal_lm', 'init_device': 'meta', 'd_model': 768, 'n_heads': 12, 'n_layers': 12, 'expansion_ratio': 4, 'max_seq_len': 2048, 'vocab_size': 50368, 'attn_config': {'attn_impl': 'triton'}}\n",
    "print(f\"tokenizer_config: {tokenizer_config}\")\n",
    "print(f\"model: {model_config}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer_config: {'name': 'decoupled_adamw', 'lr': 0.0006, 'betas': [0.9, 0.95], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "scheduler_config: {'name': 'cosine_with_warmup', 't_warmup': '100ba', 'alpha_f': 0.1}\n",
      "train_loader_config: {'name': 'text', 'dataset': {'local': './my-copy-c4', 'remote': None, 'split': 'train', 'shuffle': True, 'max_seq_len': 2048, 'shuffle_seed': 17}, 'drop_last': True, 'num_workers': 8}\n",
      "fsdp_config: {'sharding_strategy': 'FULL_SHARD', 'mixed_precision': 'PURE', 'activation_checkpointing': False, 'activation_checkpointing_reentrant': False, 'activation_cpu_offload': False, 'limit_all_gathers': True}\n",
      "eval_loader_config: {'name': 'text', 'dataset': {'local': './my-copy-c4', 'remote': None, 'split': 'val', 'shuffle': False, 'max_seq_len': 2048, 'shuffle_seed': 17}, 'drop_last': False, 'num_workers': 8}\n",
      "icl_tasks_config: None\n"
     ]
    }
   ],
   "source": [
    "# optimizer_config: {'name': 'decoupled_adamw', 'lr': 0.0006, 'betas': [0.9, 0.95], 'eps': 1e-08, 'weight_decay': 0.0}\n",
    "optimizer_config: Dict[str, Any] = pop_config(cfg,\n",
    "                                                  'optimizer',\n",
    "                                                  must_exist=True,\n",
    "                                                  convert=True)\n",
    "# scheduler_config: {'name': 'cosine_with_warmup', 't_warmup': '100ba', 'alpha_f': 0.1}\n",
    "scheduler_config: Dict[str, Any] = pop_config(cfg,\n",
    "                                                  'scheduler',\n",
    "                                                  must_exist=True,\n",
    "                                                  convert=True)\n",
    "# train_loader_config: {'name': 'text', 'dataset': {'local': './my-copy-c4', 'remote': None, 'split': 'train', 'shuffle': True, 'max_seq_len': 2048, 'shuffle_seed': 17}, 'drop_last': True, 'num_workers': 8}\n",
    "train_loader_config: DictConfig = pop_config(cfg,\n",
    "                                                 'train_loader',\n",
    "                                                 must_exist=True)\n",
    "\n",
    "# fsdp_config: {'sharding_strategy': 'FULL_SHARD', 'mixed_precision': 'PURE', 'activation_checkpointing': False, 'activation_checkpointing_reentrant': False, 'activation_cpu_offload': False, 'limit_all_gathers': True}\n",
    "fsdp_config: Optional[Dict[str, Any]] = pop_config(cfg,\n",
    "                                                       'fsdp_config',\n",
    "                                                       must_exist=False,\n",
    "                                                       default_value=None,\n",
    "                                                       convert=True)\n",
    "# eval_loader_config: {'name': 'text', 'dataset': {'local': './my-copy-c4', 'remote': None, 'split': 'val', 'shuffle': False, 'max_seq_len': 2048, 'shuffle_seed': 17}, 'drop_last': False, 'num_workers': 8}\n",
    "eval_loader_config: Optional[Union[DictConfig, ListConfig]] = pop_config(\n",
    "        cfg, 'eval_loader', must_exist=False, default_value=None)\n",
    "\n",
    "# icl_tasks_config: None\n",
    "icl_tasks_config: Optional[Union[ListConfig,\n",
    "                                     str]] = pop_config(cfg,\n",
    "                                                        'icl_tasks',\n",
    "                                                        must_exist=False,\n",
    "                                                        default_value=None)\n",
    "\n",
    "\n",
    "print(f\"optimizer_config: {optimizer_config}\")\n",
    "print(f\"scheduler_config: {scheduler_config}\")\n",
    "print(f\"train_loader_config: {train_loader_config}\")\n",
    "print(f\"fsdp_config: {fsdp_config}\")\n",
    "print(f\"eval_loader_config: {eval_loader_config}\")\n",
    "print(f\"icl_tasks_config: {icl_tasks_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_gauntlet_config: None, icl_subset_num_batches: None, icl_seq_len: None\n",
      "loggers: None, callbacks: {'speed_monitor': {'window_size': 10}, 'lr_monitor': {}, 'memory_monitor': {}, 'runtime_estimator': {}}, algorithms: {'gradient_clipping': {'clipping_type': 'norm', 'clipping_threshold': 1.0}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">35</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"loggers: {</span>logger_configs<span style=\"color: #808000; text-decoration-color: #808000\">}, callbacks: {</span>callback_configs<span style=\"color: #808000; text-decoration-color: #808000\">}, algorithms: {</span>algorithm    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 # Mandatory hyperparameters for training</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>35 device_train_batch_size: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span> = pop_config(cfg,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">'device_train_batch_size'</span>,                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │     </span>must_exist=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 </span>device_eval_batch_size: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span> = pop_config(cfg,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/yu.gong/miniconda3/envs/mosaic2/lib/python3.10/site-packages/llmfoundry/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">config_util</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">s.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">42</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pop_config</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> value                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> must_exist:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 42 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NameError</span>(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f'The {</span>key<span style=\"color: #808000; text-decoration-color: #808000\">} parameter is missing and must exist for execution. Please check </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>The device_train_batch_size parameter is missing and must exist for execution. Please check your yaml.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m35\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mloggers: \u001b[0m\u001b[33m{\u001b[0mlogger_configs\u001b[33m}\u001b[0m\u001b[33m, callbacks: \u001b[0m\u001b[33m{\u001b[0mcallback_configs\u001b[33m}\u001b[0m\u001b[33m, algorithms: \u001b[0m\u001b[33m{\u001b[0malgorithm    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m# Mandatory hyperparameters for training\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m35 device_train_batch_size: \u001b[96mint\u001b[0m = pop_config(cfg,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │     \u001b[0m\u001b[33m'\u001b[0m\u001b[33mdevice_train_batch_size\u001b[0m\u001b[33m'\u001b[0m,                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │     \u001b[0mmust_exist=\u001b[94mTrue\u001b[0m)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0mdevice_eval_batch_size: \u001b[96mint\u001b[0m = pop_config(cfg,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/yu.gong/miniconda3/envs/mosaic2/lib/python3.10/site-packages/llmfoundry/utils/\u001b[0m\u001b[1;33mconfig_util\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33ms.py\u001b[0m:\u001b[94m42\u001b[0m in \u001b[92mpop_config\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 39 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m value                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m must_exist:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 42 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNameError\u001b[0m(                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mThe \u001b[0m\u001b[33m{\u001b[0mkey\u001b[33m}\u001b[0m\u001b[33m parameter is missing and must exist for execution. Please check \u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mThe device_train_batch_size parameter is missing and must exist for execution. Please check your yaml.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_gauntlet_config: Optional[Union[DictConfig,\n",
    "                                         str]] = pop_config(cfg,\n",
    "                                                            'eval_gauntlet',\n",
    "                                                            must_exist=False,\n",
    "                                                            default_value=None)\n",
    "icl_subset_num_batches: Optional[int] = pop_config(cfg,\n",
    "    \n",
    "                                                       'icl_subset_num_batches',\n",
    "                                                       must_exist=False,\n",
    "                                                       default_value=None)\n",
    "icl_seq_len: Optional[int] = pop_config(cfg,\n",
    "                                            'icl_seq_len',\n",
    "                                            must_exist=False,\n",
    "                                            default_value=None)\n",
    "# eval_gauntlet_config: None, icl_subset_num_batches: None, icl_seq_len: None\n",
    "print(f\"eval_gauntlet_config: {eval_gauntlet_config}, icl_subset_num_batches: {icl_subset_num_batches}, icl_seq_len: {icl_seq_len}\")\n",
    "\n",
    "# Optional logging, evaluation and callback configs\n",
    "logger_configs: Optional[DictConfig] = pop_config(cfg,\n",
    "                                                      'loggers',\n",
    "                                                      must_exist=False,\n",
    "                                                      default_value=None,\n",
    "                                                      convert=True)\n",
    "callback_configs: Optional[DictConfig] = pop_config(cfg,\n",
    "                                                        'callbacks',\n",
    "                                                        must_exist=False,\n",
    "                                                        default_value=None,\n",
    "                                                        convert=True)\n",
    "algorithm_configs: Optional[DictConfig] = pop_config(cfg,\n",
    "                                                         'algorithms',\n",
    "                                                         must_exist=False,\n",
    "                                                         default_value=None)\n",
    "# loggers: None, callbacks: {'speed_monitor': {'window_size': 10}, 'lr_monitor': {}, 'memory_monitor': {}, 'runtime_estimator': {}}, algorithms: {'gradient_clipping': {'clipping_type': 'norm', 'clipping_threshold': 1.0}}\n",
    "print(f\"loggers: {logger_configs}, callbacks: {callback_configs}, algorithms: {algorithm_configs}\")\n",
    "\n",
    "# Mandatory hyperparameters for training\n",
    "device_train_batch_size: int = pop_config(cfg,\n",
    "                                              'device_train_batch_size',\n",
    "                                              must_exist=True)\n",
    "device_eval_batch_size: int = pop_config(cfg,\n",
    "                                             'device_eval_batch_size',\n",
    "                                             must_exist=True)\n",
    "max_duration: Union[int, str] = pop_config(cfg,\n",
    "                                               'max_duration',\n",
    "                                               must_exist=True)\n",
    "eval_interval: Union[int, str] = pop_config(cfg,\n",
    "                                                'eval_interval',\n",
    "                                                default_value=1,\n",
    "                                                must_exist=False)\n",
    "precision: str = pop_config(cfg, 'precision', must_exist=True)\n",
    "max_seq_len: int = pop_config(cfg, 'max_seq_len', must_exist=True)\n",
    "\n",
    "print(f\"device_train_batch_size: {device_train_batch_size}, device_eval_batch_size: {device_eval_batch_size}, max_duration: {max_duration}, eval_interval: {eval_interval}, precision: {precision}, max_seq_len: {max_seq_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaic2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
