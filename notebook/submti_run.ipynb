{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up the Credentials\n",
    "-----------------------\n",
    "Set the up the credentials to submit the runs to `r1z1` cluster\n",
    "\n",
    "This step is not needed in Databricks Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CREDENTIALS has been preset with `conda env config vars set CREDENTIALS=\"xxs\"`\n",
    "\n",
    "# To generate CREDENTIALS for your local environment, you can use the following command:\n",
    "# data = {\n",
    "#     \"workspace_url\": \"https://dbc-04ac0685-8857.staging.cloud.databricks.com/\",\n",
    "#     \"token\": \"dapi338xx\", \n",
    "#     \"mosaic_token\": \"Y4x7xx\",\n",
    "# }\n",
    "# data = json.dumps(data)\n",
    "# credentials = base64.b64encode(data.encode('utf-8')).decode('utf-8')\n",
    "\n",
    "import os\n",
    "from ygong.mosaic import submit, _set_up_environment\n",
    "\n",
    "credentials = os.environ.get(\"CREDENTIALS\")\n",
    "_set_up_environment(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Testing \n",
    "------------------\n",
    "Run the trainer.fit locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'train' from '/Users/yu.gong/workspace/mosaic/custom-train-demo/src/train.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# always reload for local updates to take effect\n",
    "import train\n",
    "importlib.reload(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"custom-train-demo\", \"seed\": 42, \"dist_timeout\": 600.0, \"global_train_batch_size\": 4, \"device_train_microbatch_size\": 16}\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "import json\n",
    "name = \"custom-train-demo\"\n",
    "config = train.MyConfig(global_train_batch_size=4, name=name)\n",
    "json_str = json.dumps(asdict(config))\n",
    "print(json_str)\n",
    "# train.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "train.main(config)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit Run \n",
    "----------\n",
    "\n",
    "run the local train.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone -b prototype \"https://github.com/ygong1/llm-foundry.git\" llm-foundry\n",
    "# cd llm-foundry && pip install -e .[gpu] && cd ..\n",
    "# git clone https://github.com/ygong1/custom-train-demo.git\n",
    "# ../llm-foundry/scripts/train/launcher.py ./src/train.py  '{\"seed\": 42, \"dist_timeout\": 600.0, \"global_train_batch_size\": 1024, \"device_train_microbatch_size\": 16}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcli import RunConfig\n",
    "from ygong.mosaic import ScalingConfig\n",
    "from ygong.mosaic import submit\n",
    "\n",
    "config = train.MyConfig(global_train_batch_size=4, name=name)\n",
    "json_str = json.dumps(asdict(config))\n",
    "commands = [\n",
    "    \"cd ~/custom-train-demo\",\n",
    "    f'''~/llm-foundry/scripts/train/launcher.py ./src/train.py  '{json_str}' '''\n",
    "]\n",
    "\n",
    "scalingConfig = ScalingConfig(gpusNum=8, gpuType=\"a100_80gb\", poolName=\"r1z1\")\n",
    "\n",
    "config = RunConfig(\n",
    "    name=\"custom-train-demo\",\n",
    "    image='mosaicml/llm-foundry:2.2.1_cu121_flash2-latest',\n",
    "    command=\"\\n\".join(commands),\n",
    "    compute=scalingConfig.toCompute,\n",
    "    integrations=[\n",
    "                {\n",
    "                   'integration_type': 'git_repo',\n",
    "                   'git_repo': 'ygong1/llm-foundry',\n",
    "                   'path': '~/llm-foundry',\n",
    "                   'git_branch': 'prototype',\n",
    "                   'pip_install': '-e .[gpu]',\n",
    "                   'ssh_clone': False\n",
    "                },\n",
    "                {\n",
    "                   'integration_type': 'git_repo',\n",
    "                   'git_repo': 'ygong1/custom-train-demo',\n",
    "                   'path': '~/custom-train-demo',\n",
    "                   'ssh_clone': False\n",
    "                },\n",
    "                {\n",
    "                   'integration_type': 'pip_packages',\n",
    "                   'packages': ['pynvml', 'mosaicml-streaming[databricks]'],\n",
    "                },\n",
    "    ],\n",
    "    env_variables={},\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b145b080004f3bbf9f92ab3d5354b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='cancel the run', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run Name</th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Experiment Run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>custom-train-demo-oL1IFf</td>\n",
       "      <td>31bc887b-af62-4081-8026-3ad670c742f4</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-24 16:24:12,290 - ygong.mosaic.submit - DEBUG - waiting for the MLFLow experiment run to be ready, run statusRUNNING\n",
      "2024-03-24 16:24:12,290 - ygong.mosaic.submit - DEBUG - waiting for the MLFLow experiment run to be ready, run statusRUNNING\n",
      "2024-03-24 16:24:33,057 - ygong.mosaic.submit - DEBUG - run custom-train-demo-oL1IFf is terminated. Status TERMINATING\n",
      "2024-03-24 16:24:33,057 - ygong.mosaic.submit - DEBUG - run custom-train-demo-oL1IFf is terminated. Status TERMINATING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Run(run_uid='31bc887b-af62-4081-8026-3ad670c742f4', name='custom-train-demo-oL1IFf', status=<RunStatus.TERMINATING: 'TERMINATING'>, created_at=datetime.datetime(2024, 3, 24, 23, 23, 33, 609000, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 3, 24, 23, 23, 33, 609000, tzinfo=datetime.timezone.utc), created_by='yu.gong@databricks.com', priority='MEDIUM', preemptible=False, retry_on_system_failure=False, cluster='r1z1', gpus=8, gpu_type='a100_80gb', cpus=0, node_count=1, latest_resumption=Resumption(index=0, cluster='r1z1', gpus=8, cpus=0, gpu_type='a100_80gb', node_count=1, status=<RunStatus.TERMINATING: 'TERMINATING'>, estimated_end_time=None, started_at=datetime.datetime(2024, 3, 24, 23, 23, 42, tzinfo=datetime.timezone.utc), ended_at=datetime.datetime(2024, 3, 24, 23, 24, 19, tzinfo=datetime.timezone.utc), reason=''), is_deleted=False, run_type=<RunType.TRAINING: 'TRAINING'>, max_retries=0, reason='', nodes=[Node(rank=0, name='a100-80sxm-h11-01', status='FAILED', reason='Exit code: 127. Reason: Error')], submitted_config=RunConfig(name='custom-train-demo', parent_name=None, image='mosaicml/llm-foundry:2.2.1_cu121_flash2-latest', gpu_type=None, gpu_num=None, cpus=0, cluster=None, scheduling={}, compute={'gpus': 8, 'cluster': 'r1z1', 'gpu_type': 'a100_80gb'}, parameters={}, integrations=[{'integration_type': 'git_repo', 'path': '~/llm-foundry', 'git_repo': 'ygong1/llm-foundry', 'ssh_clone': False, 'git_branch': 'prototype', 'pip_install': '-e .[gpu]'}, {'integration_type': 'git_repo', 'path': '~/custom-train-demo', 'git_repo': 'ygong1/custom-train-demo', 'ssh_clone': False}, {'integration_type': 'pip_packages', 'packages': ['pynvml', 'mosaicml-streaming[databricks]']}], env_variables={}, metadata={}, command='cd ~/custom-train-demo\\n./llm-foundry/scripts/train/launcher.py ./src/train.py  \\'{\"name\": \"custom-train-demo\", \"seed\": 42, \"dist_timeout\": 600.0, \"global_train_batch_size\": 4, \"device_train_microbatch_size\": 16}\\'', dependent_deployment={}, _suppress_deprecation_warnings=None), metadata={}, last_resumption_id='60036240-d0be-411e-95fb-9f223dd5e24d', resumptions=[Resumption(index=0, cluster='r1z1', gpus=8, cpus=0, gpu_type='a100_80gb', node_count=1, status=<RunStatus.TERMINATING: 'TERMINATING'>, estimated_end_time=None, started_at=datetime.datetime(2024, 3, 24, 23, 23, 42, tzinfo=datetime.timezone.utc), ended_at=datetime.datetime(2024, 3, 24, 23, 24, 19, tzinfo=datetime.timezone.utc), reason='')], lifecycle=[RunLifecycle(resumption_id=0, status=<RunStatus.PENDING: 'PENDING'>, started_at=datetime.datetime(2024, 3, 24, 23, 23, 33, 609000, tzinfo=datetime.timezone.utc), ended_at=datetime.datetime(2024, 3, 24, 23, 23, 42, tzinfo=datetime.timezone.utc), reason=None, estimated_end_time=None), RunLifecycle(resumption_id=0, status=<RunStatus.RUNNING: 'RUNNING'>, started_at=datetime.datetime(2024, 3, 24, 23, 23, 42, tzinfo=datetime.timezone.utc), ended_at=datetime.datetime(2024, 3, 24, 23, 24, 19, tzinfo=datetime.timezone.utc), reason=None, estimated_end_time=None), RunLifecycle(resumption_id=0, status=<RunStatus.TERMINATING: 'TERMINATING'>, started_at=datetime.datetime(2024, 3, 24, 23, 24, 19, tzinfo=datetime.timezone.utc), ended_at=None, reason='', estimated_end_time=None)], image='mosaicml/llm-foundry:2.2.1_cu121_flash2-latest', max_duration=None, _required_properties=('id', 'name', 'status', 'createdAt', 'updatedAt', 'reason', 'createdByEmail', 'priority', 'preemptible', 'retryOnSystemFailure', 'resumptions', 'isDeleted', 'runType'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit(None, config, scalingConfig, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaic2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
